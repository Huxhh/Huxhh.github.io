{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/Anisina/source/css/blog-style.css","path":"css/blog-style.css","modified":1,"renderable":1},{"_id":"themes/Anisina/source/css/syntax.styl","path":"css/syntax.styl","modified":1,"renderable":1},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.eot","path":"fonts/glyphicons-halflings-regular.eot","modified":1,"renderable":1},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.ttf","path":"fonts/glyphicons-halflings-regular.ttf","modified":1,"renderable":1},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.woff","path":"fonts/glyphicons-halflings-regular.woff","modified":1,"renderable":1},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.woff2","path":"fonts/glyphicons-halflings-regular.woff2","modified":1,"renderable":1},{"_id":"themes/Anisina/source/js/blog.js","path":"js/blog.js","modified":1,"renderable":1},{"_id":"themes/Anisina/source/js/bootstrap.min.js","path":"js/bootstrap.min.js","modified":1,"renderable":1},{"_id":"themes/Anisina/source/js/jquery.tagcloud.js","path":"js/jquery.tagcloud.js","modified":1,"renderable":1},{"_id":"themes/Anisina/source/js/totop.js","path":"js/totop.js","modified":1,"renderable":1},{"_id":"themes/Anisina/source/css/bootstrap.min.css","path":"css/bootstrap.min.css","modified":1,"renderable":1},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.svg","path":"fonts/glyphicons-halflings-regular.svg","modified":1,"renderable":1},{"_id":"themes/Anisina/source/js/jquery.min.js","path":"js/jquery.min.js","modified":1,"renderable":1},{"_id":"themes/Anisina/source/js/jquery.js","path":"js/jquery.js","modified":1,"renderable":1}],"Cache":[{"_id":"themes/Anisina/LICENSE","hash":"2b209f06bebeb2a8c2b7e187e436f3e1e1fbc8a7","modified":1536758339843},{"_id":"themes/Anisina/README.md","hash":"69a70e00c02bf563d425c8bcaf0b301a0eed5aa6","modified":1536758339844},{"_id":"themes/Anisina/_config.yml","hash":"a43301854608b138ccac1f321c7f93ee4be901bc","modified":1539918483641},{"_id":"themes/Anisina/package.json","hash":"12541fbf56f785e4f5d486a55b4939f3033f625b","modified":1536758339864},{"_id":"source/Tags/index.md","hash":"ca976599b645cfa37051d37a109005e239d49e45","modified":1540174240431},{"_id":"source/_posts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1556421108171},{"_id":"source/_posts/PyTorch分布式训练.md","hash":"899e7f131effecbce481dbf9cab723fcc517e876","modified":1556422415133},{"_id":"source/_posts/机器学习笔记（一）贝叶斯分类器.md","hash":"31f441193af94effa8d5c71093c91b93fce05ae0","modified":1540347653935},{"_id":"source/about/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1540174705617},{"_id":"source/about/index.md","hash":"cb3c53c73a5dd7029d97ace27431a85f63b92278","modified":1540175044226},{"_id":"themes/Anisina/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1536758339835},{"_id":"themes/Anisina/.git/config","hash":"050bd84e438fe3cde46d681fefd19a7d07cb0f15","modified":1536758339838},{"_id":"themes/Anisina/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1536758106311},{"_id":"themes/Anisina/.git/index","hash":"cd5206769a7088bd07316757ea0c33928e1601bb","modified":1536760023227},{"_id":"themes/Anisina/.git/packed-refs","hash":"850ed328dfe8c74f0ef8cb1bc70d5bede031b5f1","modified":1536758339832},{"_id":"themes/Anisina/.idea/Anisina.iml","hash":"4240dabdc746a36bae8a56eeec04a3a3fc59d842","modified":1536758339842},{"_id":"themes/Anisina/.idea/modules.xml","hash":"6f81355dee5b607683bdbd56595a930fb4b83c8b","modified":1536758339843},{"_id":"themes/Anisina/.idea/vcs.xml","hash":"c92f3eb0ad1c70371e177a4d7d741f90af3f902c","modified":1536758339843},{"_id":"themes/Anisina/.idea/workspace.xml","hash":"e0f2937282f1d9898ae485dc0c01b15bd7eaccfd","modified":1536758339843},{"_id":"themes/Anisina/Screenshots/mobile-index.jpeg","hash":"cd75f77f5d865d42182e2233e354eeba9f114d98","modified":1536758339845},{"_id":"themes/Anisina/layout/.DS_Store","hash":"fd623c7cbe0d8fd902f6ca242127fd8db7da6c18","modified":1536758339861},{"_id":"themes/Anisina/layout/404.ejs","hash":"1fe05722bd1b32bbe0ae4e3e880866f935e0ae11","modified":1536758339861},{"_id":"themes/Anisina/layout/index.ejs","hash":"a0eaee13571e79c3632e23a9e94ccc991761d1f5","modified":1536758339862},{"_id":"themes/Anisina/layout/layout.ejs","hash":"b728827bf3ec55baf96a882032397e6c74c65f34","modified":1536758339862},{"_id":"themes/Anisina/layout/page.ejs","hash":"e9990327469aa94a98a3dae92bdc9326a5b99c8a","modified":1536758339863},{"_id":"themes/Anisina/layout/poetry.ejs","hash":"6c955d419050825e13d39c780d45aceafbf6552d","modified":1536758339863},{"_id":"themes/Anisina/layout/post.ejs","hash":"05203c1f8414ffc237a00be77a156264df2c7971","modified":1536758339863},{"_id":"themes/Anisina/layout/tags.ejs","hash":"a5b73e70540e12532aa92f12609b3a937a8bc28b","modified":1536758339864},{"_id":"themes/Anisina/layout/works.ejs","hash":"1df954e54098cc4845295836374abed870789dcd","modified":1536758339864},{"_id":"themes/Anisina/languages_to_be_added/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1536758339859},{"_id":"themes/Anisina/languages_to_be_added/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1536758339859},{"_id":"themes/Anisina/languages_to_be_added/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1536758339859},{"_id":"themes/Anisina/languages_to_be_added/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1536758339859},{"_id":"themes/Anisina/languages_to_be_added/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1536758339859},{"_id":"themes/Anisina/languages_to_be_added/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1536758339860},{"_id":"themes/Anisina/languages_to_be_added/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1536758339860},{"_id":"themes/Anisina/languages_to_be_added/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1536758339860},{"_id":"themes/Anisina/languages_to_be_added/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1536758339860},{"_id":"themes/Anisina/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1536758106313},{"_id":"themes/Anisina/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1536758106311},{"_id":"themes/Anisina/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1536758106313},{"_id":"themes/Anisina/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1536758106314},{"_id":"themes/Anisina/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1536758106312},{"_id":"themes/Anisina/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1536758106314},{"_id":"themes/Anisina/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1536758106312},{"_id":"themes/Anisina/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1536758106313},{"_id":"themes/Anisina/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1536758106313},{"_id":"themes/Anisina/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1536758106315},{"_id":"themes/Anisina/.git/info/exclude","hash":"bb5a85730dcf100facee799c05cc4f6affec0745","modified":1536758106311},{"_id":"themes/Anisina/.git/logs/HEAD","hash":"56b0439dc6784cba85df0b0ca2bead5733c1a79d","modified":1536758339837},{"_id":"themes/Anisina/.idea/inspectionProfiles/Project_Default.xml","hash":"cb98213afbdfab7620cd4b6ba8801035079b4ae5","modified":1536758339842},{"_id":"themes/Anisina/Screenshots/Anisina.png","hash":"146dd991f55a827a514259e20a51de1e9b07a13d","modified":1536758339845},{"_id":"themes/Anisina/layout/_partial/footer.ejs","hash":"0235c9e7497e94fa036c3d21117834e4464a64e6","modified":1536758339861},{"_id":"themes/Anisina/layout/_partial/head.ejs","hash":"99cff26893ca5599fdd3ef2c7d8bb50ecab2e2d9","modified":1539918125854},{"_id":"themes/Anisina/layout/_partial/nav.ejs","hash":"3baa41d595e951efa1db34dd1789c6f8d3b094da","modified":1536758339862},{"_id":"themes/Anisina/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1536758339862},{"_id":"themes/Anisina/source/css/blog-style.css","hash":"c6830e31138e412c2aa05228c4cd6035063fe651","modified":1536758339865},{"_id":"themes/Anisina/source/css/syntax.styl","hash":"f3f9ff0d1ebc4f7fa18d7e367b2ba2f0899adbd4","modified":1536758339866},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1536758339866},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1536758339868},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1536758339868},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1536758339869},{"_id":"themes/Anisina/source/js/blog.js","hash":"0f805c744ef8a48c0abdd9d204cfc19ee6cafc14","modified":1536758339869},{"_id":"themes/Anisina/source/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1536758339869},{"_id":"themes/Anisina/source/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1536758339873},{"_id":"themes/Anisina/source/js/totop.js","hash":"11ede60fccb7c763d6973f80efc78b47c0843746","modified":1536758339873},{"_id":"themes/Anisina/Screenshots/poetry-show.png","hash":"f5fdcd25026a87a0aafeebb1f19cdb3c0a81a666","modified":1536758339858},{"_id":"themes/Anisina/source/css/bootstrap.min.css","hash":"c5db932e115ff97af7b4512b947cde3ba2964db8","modified":1536758339866},{"_id":"themes/Anisina/source/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1536758339868},{"_id":"themes/Anisina/source/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1536758339873},{"_id":"themes/Anisina/.git/objects/pack/pack-0a3cf5d407b7a0446aa4a2414e22d7347547fa50.idx","hash":"22da6e1633dc4768bfd268d388396c2c9c1ed8b6","modified":1536758339816},{"_id":"themes/Anisina/.git/refs/heads/master","hash":"248a07253021783cf98e361d4e7138d712330b61","modified":1536758339836},{"_id":"themes/Anisina/Screenshots/mobile-post.jpeg","hash":"2081cdff23a9a8c185a48d9aabcc9dc8e77833ec","modified":1536758339848},{"_id":"themes/Anisina/source/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1536758339872},{"_id":"themes/Anisina/.git/logs/refs/heads/master","hash":"56b0439dc6784cba85df0b0ca2bead5733c1a79d","modified":1536758339837},{"_id":"themes/Anisina/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1536758339835},{"_id":"themes/Anisina/Screenshots/pc-index.png","hash":"b04094dac75cb656b4244c1dfaf246168a0f8926","modified":1536758339851},{"_id":"themes/Anisina/.git/logs/refs/remotes/origin/HEAD","hash":"56b0439dc6784cba85df0b0ca2bead5733c1a79d","modified":1536758339835},{"_id":"themes/Anisina/Screenshots/pc-post.png","hash":"cde56c0797b6ff8dd555fb1f8c3f9b21bceaa3be","modified":1536758339857},{"_id":"themes/Anisina/.git/objects/pack/pack-0a3cf5d407b7a0446aa4a2414e22d7347547fa50.pack","hash":"31599716acea266f01b469b08d792dff9c5bab2b","modified":1536758339816},{"_id":"public/Tags/index.html","hash":"bc6e568c30a873f7177b45486e41aa6e1dff27d0","modified":1556422423837},{"_id":"public/about/index.html","hash":"297c94ea45e85f70a9fdffc2e588dc18d203c967","modified":1556422423837},{"_id":"public/archives/index.html","hash":"0ab4f81c099889bb4e811f5676215b5aed1f1f5f","modified":1556422423837},{"_id":"public/archives/2018/index.html","hash":"7a4c85d67b96038d4d8a26ed9c94282a79a33a9c","modified":1556422423837},{"_id":"public/archives/2018/10/index.html","hash":"515cb76b5c7d1f682f63b91376343758f1a3e988","modified":1556422423838},{"_id":"public/archives/2019/index.html","hash":"a9877e0d4d8cdf3d6cb202311045f4e50652a5b7","modified":1556422423838},{"_id":"public/archives/2019/04/index.html","hash":"c3653c62f6cc134c941258a5ca30ff0cc5340f21","modified":1556422423838},{"_id":"public/tags/PyTorch/index.html","hash":"dab0ece017a2fdac8a33a9b2cf63a8997fadf95a","modified":1556422423838},{"_id":"public/tags/Machine-Learning/index.html","hash":"d1e3cd465e26e65138290bb58849986eb0c53c60","modified":1556422423838},{"_id":"public/2019/04/28/PyTorch分布式训练/index.html","hash":"a6d018eaddcb586a5e3102c4dff218852d7b60a6","modified":1556422423838},{"_id":"public/2018/10/18/机器学习笔记（一）贝叶斯分类器/index.html","hash":"05f58a21630f15c023f6bd86bf7dcf42f09e18bf","modified":1556422423839},{"_id":"public/index.html","hash":"bd8ad2d268c713adacb45fd3a98bef3b12280394","modified":1556422423839},{"_id":"public/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1556422423843},{"_id":"public/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1556422423843},{"_id":"public/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1556422423843},{"_id":"public/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1556422423843},{"_id":"public/css/syntax.css","hash":"4616879fec214c9cc4f5835615348f0bbeabf2a9","modified":1556422423962},{"_id":"public/js/blog.js","hash":"0f805c744ef8a48c0abdd9d204cfc19ee6cafc14","modified":1556422423962},{"_id":"public/css/blog-style.css","hash":"c6830e31138e412c2aa05228c4cd6035063fe651","modified":1556422423964},{"_id":"public/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1556422423965},{"_id":"public/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1556422423968},{"_id":"public/js/totop.js","hash":"11ede60fccb7c763d6973f80efc78b47c0843746","modified":1556422423968},{"_id":"public/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1556422423968},{"_id":"public/css/bootstrap.min.css","hash":"c5db932e115ff97af7b4512b947cde3ba2964db8","modified":1556422423968},{"_id":"public/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1556422423968},{"_id":"public/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1556422423969}],"Category":[],"Data":[],"Page":[{"title":"Tags","layout":"tags","date":"2018-10-22T02:05:44.000Z","_content":"","source":"Tags/index.md","raw":"---\ntitle: Tags\nlayout: tags\ndate: 2018-10-22 10:05:44\n---\n","updated":"2018-10-22T02:10:40.431Z","path":"Tags/index.html","comments":1,"_id":"cjv0dq3rx000147od8l6iqm2a","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"about","layout":"works","date":"2018-10-22T02:17:59.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\nlayout: works\ndate: 2018-10-22 10:17:59\n---\n","updated":"2018-10-22T02:24:04.226Z","path":"about/index.html","comments":1,"_id":"cjv0dq3s0000347odsru05rz0","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"PyTorch分布式训练","date":"2019-04-28T03:11:10.000Z","_content":"\n# PyTorch分布式训练\n分布式训练已经成为如今训练深度学习模型的一个必备工具，但pytorch默认使用单个GPU进行训练，如果想用使用多个GPU乃至多个含有多块GPU的节点进行分布式训练的时候，需要在代码当中进行修改，这里总结一下几种使用pytorch进行分布式训练的方式。\n\n## 环境\n本文使用的环境为：\n\n* python =3.7\n* pytorch = 1.0\n* CUDA = 8.0\n\n## 使用单个GPU\npytorch中`pytorch.cuda`用于设置和运行`CUDA`操作，它会跟踪当前选定的GPU，并且您分配的所有CUDA张量将默认在该设备上创建。所选设备可以使用 `torch.cuda.device` 环境管理器进行更改。\npytorch中想要使用GPU进行模型训练非常简单，首先需要使用代码`torch.cuda.is_available()`判断当前环境是否可以使用GPU，如果返回`False`那么证明GPU不可用，需要检查软件包或驱动等是否安装正确。\n当GPU可用时，可以使用`torch.device()`创建一个`torch.device`对象，例如`torch.device('cuda')`或使用`torch.device('cuda:0')`指定GPU，该对象可以将张量移动至GPU上。假设有一个张量`x`，我们可以使用`x.cuda()`或`x.to(device)`的方式将其移动至GPU上，这两种方式可以视作是等价的，并没有太大的区别，Variable与模型同理，也可以使用这样的方式进行移动。接下来按照征程的操作即可以进行训练。\n\n## 单机使用多个GPU\n单机使用多个GPU有两种方式，`torch.nn.DataParallel()`与`torch.nn.parallel.DistributedDataParallel`\n其中`torch.nn.DataParallel()`智能实现在单机多卡中进行分布式训练，而`torch.nn.parallel.DistributedDataParallel`则是新方法，在单机多卡和多机多卡都可以训练。官方建议使用最新的`torch.nn.parallel.DistributedDataParallel`，因为即使在单机多卡上，新的方法在效率上也要比旧的表现好。\n### torch.nn.DataParallel()\n使用该方法的方式很简单，假设我们已经构建了一个模型`NET`，则只需要：\n\n```\nmodel = NET()\nmodel = torch.nn.DataParallel()\nmode.cuda()\n```\n\n将模型分发到各个GPU上，接下来既可以使用多个GPU同时进行训练。\n\n> 值得注意的是，这里torch是把模型输入的batch_size按照GPU的个数进行均分，因此如果希望保持与单个GPU训练时同样的batch_sizze则需要按照GPU的个数n对batch_size进行扩展到batch_size *n\n\n> 还有一点是torch默认输入的第一维是batch_size的大小，因此会直接在第一维上进行分割，因此构造batch数据时需要注意。\n\n\n### torch.nn.parallel.DistributedDataParallel（）\n`torch.nn.parallel.DistributedDataParallel`是pytorch1.0新提供的方法。该计算模型并没有采用主流的Parameter Server结构，而是直接用了Uber Horovod的形式，也是百度开源的RingAllReduce算法。算法细节此处不表。\n使用该方法首先需要进行初始化`torch.distributed.init_process_group(backend, init_method='env://', **kwargs)`，其中的参数有：\n\n* backend(str): 后端选择，包括 gloo,nccl,mpi\n* init_method(str，optional): 用来初始化包的URL, 我理解是一个用来做并发控制的共享方式\n* world_size(int, optional): 参与这个工作的进程数\n* rank(int,optional): 当前进程的rank\n* group_name(str,optional): 用来标记这组进程名的\n\n其中初始化方式有三种：\n\n1. **TCP initialization**\ntcp:// IP组播（要求所有进程都在同一个网络中）比较好理解,   以TCP协议的方式进行不同分布式进程之间的数据交流，需要设置一个端口，不同进程之间公用这一个端口，并且设置host的级别和host的数量。设计两个参数rank和world_size。其中rank为host的编号，默认0为主机，端口应该位于该主机上。world_size为分布式主机的个数。\n具体的可以初始化为：`tcp://127.0.0.1:12345`\n\n2. **Shared file-system initialization**\nfile:// 共享文件系统（要求所有进程可以访问单个文件系统）有共享文件系统可以选择 \n提供的第二种方式是文件共享，机器有共享的文件系统，故可以采用这种方式，也避免了基于TCP的网络传输。这里使用方式是使用绝对路径在指定一个共享文件系统下不存在的文件。\n具体的：`file://PathToShareFile/MultiNode`\n\n3. **Environment variable initialization**\nenv:// 环境变量（需要您手动分配等级并知道所有进程可访问节点的地址）默认是这个\n\n```\nMASTER_PORT - required; has to be a free port on machine with rank 0\nMASTER_ADDR - required (except for rank 0); address of rank 0 node\nWORLD_SIZE - required; can be set either here, or in a call to init function\nRANK - required; can be set either here, or in a call to init function\n```\n\n官方示例：\n\n```\nNode 1: (IP: 192.168.1.1, and has a free port: 1234)\n \n>>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=0 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\nNode 2:\n \n>>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=1 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\n\n```\n\n在代码中进行初始化时，需要注意的一点是由于需要创建N个进程分别运行在0到N-1号GPU上，因此需要在代码中手动进行指定代码运行的GPU号，使用如下代码：\n> torch.cuda.set_device(i)\n其中i是0到N-1中的一个。同时在代码中也应该做如下的指定操作：\n\n```\ntorch.distributed.init_process_group(backend='nccl', world_size=4, rank=, init_method='...')\nmodel = DistributedDataParallel(model, device_ids=[i], output_device=i)\n```\n\n在`torch.distributed.init_process_group()`中word_size与rank参数是必需的。代表了工作的进程数与当前进程的rank。\n接下来可以启动进行分布式训练，官方也提供了相应的启动方式。\n\n\n#### 启动方式\n在`torch.distributed`当中提供了一个用于启动的程序`torch.distributed.launch`，此帮助程序可用于为每个节点启动多个进程以进行分布式训练，它在每个训练节点上产生多个分布式训练进程。\n这个工具可以用作CPU或者GPU，如果被用于GPU，每个GPU产生一个进程进行训练。\n\n该工具既可以用来做单节点多GPU训练，也可用于多节点多GPU训练。如果是单节点多GPU，将会在单个GPU上运行一个分布式进程，据称可以非常好地改进单节点训练性能。如果用于多节点分布式训练，则通过在每个节点上产生多个进程来获得更好的多节点分布式训练性能。如果有Infiniband接口则加速比会更高。\n\n在单节点分布式训练或多节点分布式训练的两种情况下，该工具将为每个节点启动给定数量的进程（--nproc_per_node）。如果用于GPU培训，则此数字需要小于或等于当前系统上的GPU数量（nproc_per_node），并且每个进程将在从GPU 0到GPU（nproc_per_node - 1）的单个GPU上运行。\n启动的命令为：\n> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3 and all other\n           arguments of your training script\n\n**注意** 使用启动工具进行启动时，会产生`--local_rank`参数，需要在代码中使用如下类似代码处理：\n\n```\nimport argparser\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--local_rank', type=int, ...)\nargs = parser..parse_args()\n```\n\n这一参数的作用是为各个进程分配rank号，因此可以直接使用这个`local_rank`参数作为`torch.distributed.init_process_group()`当中的参数rank，同时也可以作为\n\n```\ntorch.distributed.init_process_group(backend='nccl', world_size=4, rank=, init_method='...')\nmodel = DistributedDataParallel(model, device_ids=[i], output_device=i)\n```\n\n中的i。\n\n## 多机使用多个GPU\n相比于单机使用多个GPu，最大的区别在于启动方式的不同，假设有两个节点时：\nNode 1: (IP: 192.168.1.1, and has a free port: 1234)\n\n```\n>>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=0 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\n```\n\nNode 2:\n\n```\n>>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=1 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\n```\n\n增加的参数有nnodes代表机器即节点的个数，node_rank代表节点的rank，master-addr，master_port代表主节点的地址与端口号用于通信。\n至此就介绍完了pytorch的分布式训练的基础内容。\n\n\n## 参考\nhttps://pytorch.org/docs/master/distributed.html\nhttps://blog.csdn.net/zwqjoy/article/details/89415933\nhttps://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py\nhttps://www.jianshu.com/p/be9f8b90a1b8?utm_campaign=hugo&utm_medium=reader_share&utm_content=note&utm_source=weixin-friends\nhttps://juejin.im/entry/5c5f94fd518825629a779f51\n\n\n\n\n","source":"_posts/PyTorch分布式训练.md","raw":"---\ntitle: PyTorch分布式训练\ndate: 2019-04-28 11:11:10\ntags:\n- PyTorch\n---\n\n# PyTorch分布式训练\n分布式训练已经成为如今训练深度学习模型的一个必备工具，但pytorch默认使用单个GPU进行训练，如果想用使用多个GPU乃至多个含有多块GPU的节点进行分布式训练的时候，需要在代码当中进行修改，这里总结一下几种使用pytorch进行分布式训练的方式。\n\n## 环境\n本文使用的环境为：\n\n* python =3.7\n* pytorch = 1.0\n* CUDA = 8.0\n\n## 使用单个GPU\npytorch中`pytorch.cuda`用于设置和运行`CUDA`操作，它会跟踪当前选定的GPU，并且您分配的所有CUDA张量将默认在该设备上创建。所选设备可以使用 `torch.cuda.device` 环境管理器进行更改。\npytorch中想要使用GPU进行模型训练非常简单，首先需要使用代码`torch.cuda.is_available()`判断当前环境是否可以使用GPU，如果返回`False`那么证明GPU不可用，需要检查软件包或驱动等是否安装正确。\n当GPU可用时，可以使用`torch.device()`创建一个`torch.device`对象，例如`torch.device('cuda')`或使用`torch.device('cuda:0')`指定GPU，该对象可以将张量移动至GPU上。假设有一个张量`x`，我们可以使用`x.cuda()`或`x.to(device)`的方式将其移动至GPU上，这两种方式可以视作是等价的，并没有太大的区别，Variable与模型同理，也可以使用这样的方式进行移动。接下来按照征程的操作即可以进行训练。\n\n## 单机使用多个GPU\n单机使用多个GPU有两种方式，`torch.nn.DataParallel()`与`torch.nn.parallel.DistributedDataParallel`\n其中`torch.nn.DataParallel()`智能实现在单机多卡中进行分布式训练，而`torch.nn.parallel.DistributedDataParallel`则是新方法，在单机多卡和多机多卡都可以训练。官方建议使用最新的`torch.nn.parallel.DistributedDataParallel`，因为即使在单机多卡上，新的方法在效率上也要比旧的表现好。\n### torch.nn.DataParallel()\n使用该方法的方式很简单，假设我们已经构建了一个模型`NET`，则只需要：\n\n```\nmodel = NET()\nmodel = torch.nn.DataParallel()\nmode.cuda()\n```\n\n将模型分发到各个GPU上，接下来既可以使用多个GPU同时进行训练。\n\n> 值得注意的是，这里torch是把模型输入的batch_size按照GPU的个数进行均分，因此如果希望保持与单个GPU训练时同样的batch_sizze则需要按照GPU的个数n对batch_size进行扩展到batch_size *n\n\n> 还有一点是torch默认输入的第一维是batch_size的大小，因此会直接在第一维上进行分割，因此构造batch数据时需要注意。\n\n\n### torch.nn.parallel.DistributedDataParallel（）\n`torch.nn.parallel.DistributedDataParallel`是pytorch1.0新提供的方法。该计算模型并没有采用主流的Parameter Server结构，而是直接用了Uber Horovod的形式，也是百度开源的RingAllReduce算法。算法细节此处不表。\n使用该方法首先需要进行初始化`torch.distributed.init_process_group(backend, init_method='env://', **kwargs)`，其中的参数有：\n\n* backend(str): 后端选择，包括 gloo,nccl,mpi\n* init_method(str，optional): 用来初始化包的URL, 我理解是一个用来做并发控制的共享方式\n* world_size(int, optional): 参与这个工作的进程数\n* rank(int,optional): 当前进程的rank\n* group_name(str,optional): 用来标记这组进程名的\n\n其中初始化方式有三种：\n\n1. **TCP initialization**\ntcp:// IP组播（要求所有进程都在同一个网络中）比较好理解,   以TCP协议的方式进行不同分布式进程之间的数据交流，需要设置一个端口，不同进程之间公用这一个端口，并且设置host的级别和host的数量。设计两个参数rank和world_size。其中rank为host的编号，默认0为主机，端口应该位于该主机上。world_size为分布式主机的个数。\n具体的可以初始化为：`tcp://127.0.0.1:12345`\n\n2. **Shared file-system initialization**\nfile:// 共享文件系统（要求所有进程可以访问单个文件系统）有共享文件系统可以选择 \n提供的第二种方式是文件共享，机器有共享的文件系统，故可以采用这种方式，也避免了基于TCP的网络传输。这里使用方式是使用绝对路径在指定一个共享文件系统下不存在的文件。\n具体的：`file://PathToShareFile/MultiNode`\n\n3. **Environment variable initialization**\nenv:// 环境变量（需要您手动分配等级并知道所有进程可访问节点的地址）默认是这个\n\n```\nMASTER_PORT - required; has to be a free port on machine with rank 0\nMASTER_ADDR - required (except for rank 0); address of rank 0 node\nWORLD_SIZE - required; can be set either here, or in a call to init function\nRANK - required; can be set either here, or in a call to init function\n```\n\n官方示例：\n\n```\nNode 1: (IP: 192.168.1.1, and has a free port: 1234)\n \n>>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=0 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\nNode 2:\n \n>>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=1 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\n\n```\n\n在代码中进行初始化时，需要注意的一点是由于需要创建N个进程分别运行在0到N-1号GPU上，因此需要在代码中手动进行指定代码运行的GPU号，使用如下代码：\n> torch.cuda.set_device(i)\n其中i是0到N-1中的一个。同时在代码中也应该做如下的指定操作：\n\n```\ntorch.distributed.init_process_group(backend='nccl', world_size=4, rank=, init_method='...')\nmodel = DistributedDataParallel(model, device_ids=[i], output_device=i)\n```\n\n在`torch.distributed.init_process_group()`中word_size与rank参数是必需的。代表了工作的进程数与当前进程的rank。\n接下来可以启动进行分布式训练，官方也提供了相应的启动方式。\n\n\n#### 启动方式\n在`torch.distributed`当中提供了一个用于启动的程序`torch.distributed.launch`，此帮助程序可用于为每个节点启动多个进程以进行分布式训练，它在每个训练节点上产生多个分布式训练进程。\n这个工具可以用作CPU或者GPU，如果被用于GPU，每个GPU产生一个进程进行训练。\n\n该工具既可以用来做单节点多GPU训练，也可用于多节点多GPU训练。如果是单节点多GPU，将会在单个GPU上运行一个分布式进程，据称可以非常好地改进单节点训练性能。如果用于多节点分布式训练，则通过在每个节点上产生多个进程来获得更好的多节点分布式训练性能。如果有Infiniband接口则加速比会更高。\n\n在单节点分布式训练或多节点分布式训练的两种情况下，该工具将为每个节点启动给定数量的进程（--nproc_per_node）。如果用于GPU培训，则此数字需要小于或等于当前系统上的GPU数量（nproc_per_node），并且每个进程将在从GPU 0到GPU（nproc_per_node - 1）的单个GPU上运行。\n启动的命令为：\n> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3 and all other\n           arguments of your training script\n\n**注意** 使用启动工具进行启动时，会产生`--local_rank`参数，需要在代码中使用如下类似代码处理：\n\n```\nimport argparser\n\nparser = argparse.ArgumentParser()\nparser.add_argument('--local_rank', type=int, ...)\nargs = parser..parse_args()\n```\n\n这一参数的作用是为各个进程分配rank号，因此可以直接使用这个`local_rank`参数作为`torch.distributed.init_process_group()`当中的参数rank，同时也可以作为\n\n```\ntorch.distributed.init_process_group(backend='nccl', world_size=4, rank=, init_method='...')\nmodel = DistributedDataParallel(model, device_ids=[i], output_device=i)\n```\n\n中的i。\n\n## 多机使用多个GPU\n相比于单机使用多个GPu，最大的区别在于启动方式的不同，假设有两个节点时：\nNode 1: (IP: 192.168.1.1, and has a free port: 1234)\n\n```\n>>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=0 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\n```\n\nNode 2:\n\n```\n>>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=1 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\n```\n\n增加的参数有nnodes代表机器即节点的个数，node_rank代表节点的rank，master-addr，master_port代表主节点的地址与端口号用于通信。\n至此就介绍完了pytorch的分布式训练的基础内容。\n\n\n## 参考\nhttps://pytorch.org/docs/master/distributed.html\nhttps://blog.csdn.net/zwqjoy/article/details/89415933\nhttps://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py\nhttps://www.jianshu.com/p/be9f8b90a1b8?utm_campaign=hugo&utm_medium=reader_share&utm_content=note&utm_source=weixin-friends\nhttps://juejin.im/entry/5c5f94fd518825629a779f51\n\n\n\n\n","slug":"PyTorch分布式训练","published":1,"updated":"2019-04-28T03:33:35.133Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjv0dq3rt000047odzbs3gahz","content":"<h1 id=\"pytorch分布式训练\"><a class=\"markdownIt-Anchor\" href=\"#pytorch分布式训练\"></a> PyTorch分布式训练</h1>\n<p>分布式训练已经成为如今训练深度学习模型的一个必备工具，但pytorch默认使用单个GPU进行训练，如果想用使用多个GPU乃至多个含有多块GPU的节点进行分布式训练的时候，需要在代码当中进行修改，这里总结一下几种使用pytorch进行分布式训练的方式。</p>\n<h2 id=\"环境\"><a class=\"markdownIt-Anchor\" href=\"#环境\"></a> 环境</h2>\n<p>本文使用的环境为：</p>\n<ul>\n<li>python =3.7</li>\n<li>pytorch = 1.0</li>\n<li>CUDA = 8.0</li>\n</ul>\n<h2 id=\"使用单个gpu\"><a class=\"markdownIt-Anchor\" href=\"#使用单个gpu\"></a> 使用单个GPU</h2>\n<p>pytorch中<code>pytorch.cuda</code>用于设置和运行<code>CUDA</code>操作，它会跟踪当前选定的GPU，并且您分配的所有CUDA张量将默认在该设备上创建。所选设备可以使用 <code>torch.cuda.device</code> 环境管理器进行更改。<br>\npytorch中想要使用GPU进行模型训练非常简单，首先需要使用代码<code>torch.cuda.is_available()</code>判断当前环境是否可以使用GPU，如果返回<code>False</code>那么证明GPU不可用，需要检查软件包或驱动等是否安装正确。<br>\n当GPU可用时，可以使用<code>torch.device()</code>创建一个<code>torch.device</code>对象，例如<code>torch.device('cuda')</code>或使用<code>torch.device('cuda:0')</code>指定GPU，该对象可以将张量移动至GPU上。假设有一个张量<code>x</code>，我们可以使用<code>x.cuda()</code>或<code>x.to(device)</code>的方式将其移动至GPU上，这两种方式可以视作是等价的，并没有太大的区别，Variable与模型同理，也可以使用这样的方式进行移动。接下来按照征程的操作即可以进行训练。</p>\n<h2 id=\"单机使用多个gpu\"><a class=\"markdownIt-Anchor\" href=\"#单机使用多个gpu\"></a> 单机使用多个GPU</h2>\n<p>单机使用多个GPU有两种方式，<code>torch.nn.DataParallel()</code>与<code>torch.nn.parallel.DistributedDataParallel</code><br>\n其中<code>torch.nn.DataParallel()</code>智能实现在单机多卡中进行分布式训练，而<code>torch.nn.parallel.DistributedDataParallel</code>则是新方法，在单机多卡和多机多卡都可以训练。官方建议使用最新的<code>torch.nn.parallel.DistributedDataParallel</code>，因为即使在单机多卡上，新的方法在效率上也要比旧的表现好。</p>\n<h3 id=\"torchnndataparallel\"><a class=\"markdownIt-Anchor\" href=\"#torchnndataparallel\"></a> torch.nn.DataParallel()</h3>\n<p>使用该方法的方式很简单，假设我们已经构建了一个模型<code>NET</code>，则只需要：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model = NET()</span><br><span class=\"line\">model = torch.nn.DataParallel()</span><br><span class=\"line\">mode.cuda()</span><br></pre></td></tr></table></figure>\n<p>将模型分发到各个GPU上，接下来既可以使用多个GPU同时进行训练。</p>\n<blockquote>\n<p>值得注意的是，这里torch是把模型输入的batch_size按照GPU的个数进行均分，因此如果希望保持与单个GPU训练时同样的batch_sizze则需要按照GPU的个数n对batch_size进行扩展到batch_size *n</p>\n</blockquote>\n<blockquote>\n<p>还有一点是torch默认输入的第一维是batch_size的大小，因此会直接在第一维上进行分割，因此构造batch数据时需要注意。</p>\n</blockquote>\n<h3 id=\"torchnnparalleldistributeddataparallel\"><a class=\"markdownIt-Anchor\" href=\"#torchnnparalleldistributeddataparallel\"></a> torch.nn.parallel.DistributedDataParallel（）</h3>\n<p><code>torch.nn.parallel.DistributedDataParallel</code>是pytorch1.0新提供的方法。该计算模型并没有采用主流的Parameter Server结构，而是直接用了Uber Horovod的形式，也是百度开源的RingAllReduce算法。算法细节此处不表。<br>\n使用该方法首先需要进行初始化<code>torch.distributed.init_process_group(backend, init_method='env://', **kwargs)</code>，其中的参数有：</p>\n<ul>\n<li>backend(str): 后端选择，包括 gloo,nccl,mpi</li>\n<li>init_method(str，optional): 用来初始化包的URL, 我理解是一个用来做并发控制的共享方式</li>\n<li>world_size(int, optional): 参与这个工作的进程数</li>\n<li>rank(int,optional): 当前进程的rank</li>\n<li>group_name(str,optional): 用来标记这组进程名的</li>\n</ul>\n<p>其中初始化方式有三种：</p>\n<ol>\n<li>\n<p><strong>TCP initialization</strong><br>\ntcp:// IP组播（要求所有进程都在同一个网络中）比较好理解,   以TCP协议的方式进行不同分布式进程之间的数据交流，需要设置一个端口，不同进程之间公用这一个端口，并且设置host的级别和host的数量。设计两个参数rank和world_size。其中rank为host的编号，默认0为主机，端口应该位于该主机上。world_size为分布式主机的个数。<br>\n具体的可以初始化为：<code>tcp://127.0.0.1:12345</code></p>\n</li>\n<li>\n<p><strong>Shared file-system initialization</strong><br>\nfile:// 共享文件系统（要求所有进程可以访问单个文件系统）有共享文件系统可以选择<br>\n提供的第二种方式是文件共享，机器有共享的文件系统，故可以采用这种方式，也避免了基于TCP的网络传输。这里使用方式是使用绝对路径在指定一个共享文件系统下不存在的文件。<br>\n具体的：<code>file://PathToShareFile/MultiNode</code></p>\n</li>\n<li>\n<p><strong>Environment variable initialization</strong><br>\nenv:// 环境变量（需要您手动分配等级并知道所有进程可访问节点的地址）默认是这个</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MASTER_PORT - required; has to be a free port on machine with rank 0</span><br><span class=\"line\">MASTER_ADDR - required (except for rank 0); address of rank 0 node</span><br><span class=\"line\">WORLD_SIZE - required; can be set either here, or in a call to init function</span><br><span class=\"line\">RANK - required; can be set either here, or in a call to init function</span><br></pre></td></tr></table></figure>\n<p>官方示例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Node 1: (IP: 192.168.1.1, and has a free port: 1234)</span><br><span class=\"line\"> </span><br><span class=\"line\">&gt;&gt;&gt; python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE</span><br><span class=\"line\">           --nnodes=2 --node_rank=0 --master_addr=&quot;192.168.1.1&quot;</span><br><span class=\"line\">           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3</span><br><span class=\"line\">           and all other arguments of your training script)</span><br><span class=\"line\">Node 2:</span><br><span class=\"line\"> </span><br><span class=\"line\">&gt;&gt;&gt; python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE</span><br><span class=\"line\">           --nnodes=2 --node_rank=1 --master_addr=&quot;192.168.1.1&quot;</span><br><span class=\"line\">           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3</span><br><span class=\"line\">           and all other arguments of your training script)</span><br></pre></td></tr></table></figure>\n<p>在代码中进行初始化时，需要注意的一点是由于需要创建N个进程分别运行在0到N-1号GPU上，因此需要在代码中手动进行指定代码运行的GPU号，使用如下代码：</p>\n<blockquote>\n<p>torch.cuda.set_device(i)<br>\n其中i是0到N-1中的一个。同时在代码中也应该做如下的指定操作：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.distributed.init_process_group(backend=&apos;nccl&apos;, world_size=4, rank=, init_method=&apos;...&apos;)</span><br><span class=\"line\">model = DistributedDataParallel(model, device_ids=[i], output_device=i)</span><br></pre></td></tr></table></figure>\n<p>在<code>torch.distributed.init_process_group()</code>中word_size与rank参数是必需的。代表了工作的进程数与当前进程的rank。<br>\n接下来可以启动进行分布式训练，官方也提供了相应的启动方式。</p>\n<h4 id=\"启动方式\"><a class=\"markdownIt-Anchor\" href=\"#启动方式\"></a> 启动方式</h4>\n<p>在<code>torch.distributed</code>当中提供了一个用于启动的程序<code>torch.distributed.launch</code>，此帮助程序可用于为每个节点启动多个进程以进行分布式训练，它在每个训练节点上产生多个分布式训练进程。<br>\n这个工具可以用作CPU或者GPU，如果被用于GPU，每个GPU产生一个进程进行训练。</p>\n<p>该工具既可以用来做单节点多GPU训练，也可用于多节点多GPU训练。如果是单节点多GPU，将会在单个GPU上运行一个分布式进程，据称可以非常好地改进单节点训练性能。如果用于多节点分布式训练，则通过在每个节点上产生多个进程来获得更好的多节点分布式训练性能。如果有Infiniband接口则加速比会更高。</p>\n<p>在单节点分布式训练或多节点分布式训练的两种情况下，该工具将为每个节点启动给定数量的进程（–nproc_per_node）。如果用于GPU培训，则此数字需要小于或等于当前系统上的GPU数量（nproc_per_node），并且每个进程将在从GPU 0到GPU（nproc_per_node - 1）的单个GPU上运行。<br>\n启动的命令为：</p>\n<blockquote>\n<p>python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE<br>\nYOUR_TRAINING_SCRIPT.py (–arg1 --arg2 --arg3 and all other<br>\narguments of your training script</p>\n</blockquote>\n<p><strong>注意</strong> 使用启动工具进行启动时，会产生<code>--local_rank</code>参数，需要在代码中使用如下类似代码处理：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import argparser</span><br><span class=\"line\"></span><br><span class=\"line\">parser = argparse.ArgumentParser()</span><br><span class=\"line\">parser.add_argument(&apos;--local_rank&apos;, type=int, ...)</span><br><span class=\"line\">args = parser..parse_args()</span><br></pre></td></tr></table></figure>\n<p>这一参数的作用是为各个进程分配rank号，因此可以直接使用这个<code>local_rank</code>参数作为<code>torch.distributed.init_process_group()</code>当中的参数rank，同时也可以作为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.distributed.init_process_group(backend=&apos;nccl&apos;, world_size=4, rank=, init_method=&apos;...&apos;)</span><br><span class=\"line\">model = DistributedDataParallel(model, device_ids=[i], output_device=i)</span><br></pre></td></tr></table></figure>\n<p>中的i。</p>\n<h2 id=\"多机使用多个gpu\"><a class=\"markdownIt-Anchor\" href=\"#多机使用多个gpu\"></a> 多机使用多个GPU</h2>\n<p>相比于单机使用多个GPu，最大的区别在于启动方式的不同，假设有两个节点时：<br>\nNode 1: (IP: 192.168.1.1, and has a free port: 1234)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE</span><br><span class=\"line\">           --nnodes=2 --node_rank=0 --master_addr=&quot;192.168.1.1&quot;</span><br><span class=\"line\">           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3</span><br><span class=\"line\">           and all other arguments of your training script)</span><br></pre></td></tr></table></figure>\n<p>Node 2:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE</span><br><span class=\"line\">           --nnodes=2 --node_rank=1 --master_addr=&quot;192.168.1.1&quot;</span><br><span class=\"line\">           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3</span><br><span class=\"line\">           and all other arguments of your training script)</span><br></pre></td></tr></table></figure>\n<p>增加的参数有nnodes代表机器即节点的个数，node_rank代表节点的rank，master-addr，master_port代表主节点的地址与端口号用于通信。<br>\n至此就介绍完了pytorch的分布式训练的基础内容。</p>\n<h2 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h2>\n<p><a href=\"https://pytorch.org/docs/master/distributed.html\" target=\"_blank\" rel=\"noopener\">https://pytorch.org/docs/master/distributed.html</a><br>\n<a href=\"https://blog.csdn.net/zwqjoy/article/details/89415933\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zwqjoy/article/details/89415933</a><br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py\" target=\"_blank\" rel=\"noopener\">https://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py</a><br>\n<a href=\"https://www.jianshu.com/p/be9f8b90a1b8?utm_campaign=hugo&amp;utm_medium=reader_share&amp;utm_content=note&amp;utm_source=weixin-friends\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/be9f8b90a1b8?utm_campaign=hugo&amp;utm_medium=reader_share&amp;utm_content=note&amp;utm_source=weixin-friends</a><br>\n<a href=\"https://juejin.im/entry/5c5f94fd518825629a779f51\" target=\"_blank\" rel=\"noopener\">https://juejin.im/entry/5c5f94fd518825629a779f51</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"pytorch分布式训练\"><a class=\"markdownIt-Anchor\" href=\"#pytorch分布式训练\"></a> PyTorch分布式训练</h1>\n<p>分布式训练已经成为如今训练深度学习模型的一个必备工具，但pytorch默认使用单个GPU进行训练，如果想用使用多个GPU乃至多个含有多块GPU的节点进行分布式训练的时候，需要在代码当中进行修改，这里总结一下几种使用pytorch进行分布式训练的方式。</p>\n<h2 id=\"环境\"><a class=\"markdownIt-Anchor\" href=\"#环境\"></a> 环境</h2>\n<p>本文使用的环境为：</p>\n<ul>\n<li>python =3.7</li>\n<li>pytorch = 1.0</li>\n<li>CUDA = 8.0</li>\n</ul>\n<h2 id=\"使用单个gpu\"><a class=\"markdownIt-Anchor\" href=\"#使用单个gpu\"></a> 使用单个GPU</h2>\n<p>pytorch中<code>pytorch.cuda</code>用于设置和运行<code>CUDA</code>操作，它会跟踪当前选定的GPU，并且您分配的所有CUDA张量将默认在该设备上创建。所选设备可以使用 <code>torch.cuda.device</code> 环境管理器进行更改。<br>\npytorch中想要使用GPU进行模型训练非常简单，首先需要使用代码<code>torch.cuda.is_available()</code>判断当前环境是否可以使用GPU，如果返回<code>False</code>那么证明GPU不可用，需要检查软件包或驱动等是否安装正确。<br>\n当GPU可用时，可以使用<code>torch.device()</code>创建一个<code>torch.device</code>对象，例如<code>torch.device('cuda')</code>或使用<code>torch.device('cuda:0')</code>指定GPU，该对象可以将张量移动至GPU上。假设有一个张量<code>x</code>，我们可以使用<code>x.cuda()</code>或<code>x.to(device)</code>的方式将其移动至GPU上，这两种方式可以视作是等价的，并没有太大的区别，Variable与模型同理，也可以使用这样的方式进行移动。接下来按照征程的操作即可以进行训练。</p>\n<h2 id=\"单机使用多个gpu\"><a class=\"markdownIt-Anchor\" href=\"#单机使用多个gpu\"></a> 单机使用多个GPU</h2>\n<p>单机使用多个GPU有两种方式，<code>torch.nn.DataParallel()</code>与<code>torch.nn.parallel.DistributedDataParallel</code><br>\n其中<code>torch.nn.DataParallel()</code>智能实现在单机多卡中进行分布式训练，而<code>torch.nn.parallel.DistributedDataParallel</code>则是新方法，在单机多卡和多机多卡都可以训练。官方建议使用最新的<code>torch.nn.parallel.DistributedDataParallel</code>，因为即使在单机多卡上，新的方法在效率上也要比旧的表现好。</p>\n<h3 id=\"torchnndataparallel\"><a class=\"markdownIt-Anchor\" href=\"#torchnndataparallel\"></a> torch.nn.DataParallel()</h3>\n<p>使用该方法的方式很简单，假设我们已经构建了一个模型<code>NET</code>，则只需要：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">model = NET()</span><br><span class=\"line\">model = torch.nn.DataParallel()</span><br><span class=\"line\">mode.cuda()</span><br></pre></td></tr></table></figure>\n<p>将模型分发到各个GPU上，接下来既可以使用多个GPU同时进行训练。</p>\n<blockquote>\n<p>值得注意的是，这里torch是把模型输入的batch_size按照GPU的个数进行均分，因此如果希望保持与单个GPU训练时同样的batch_sizze则需要按照GPU的个数n对batch_size进行扩展到batch_size *n</p>\n</blockquote>\n<blockquote>\n<p>还有一点是torch默认输入的第一维是batch_size的大小，因此会直接在第一维上进行分割，因此构造batch数据时需要注意。</p>\n</blockquote>\n<h3 id=\"torchnnparalleldistributeddataparallel\"><a class=\"markdownIt-Anchor\" href=\"#torchnnparalleldistributeddataparallel\"></a> torch.nn.parallel.DistributedDataParallel（）</h3>\n<p><code>torch.nn.parallel.DistributedDataParallel</code>是pytorch1.0新提供的方法。该计算模型并没有采用主流的Parameter Server结构，而是直接用了Uber Horovod的形式，也是百度开源的RingAllReduce算法。算法细节此处不表。<br>\n使用该方法首先需要进行初始化<code>torch.distributed.init_process_group(backend, init_method='env://', **kwargs)</code>，其中的参数有：</p>\n<ul>\n<li>backend(str): 后端选择，包括 gloo,nccl,mpi</li>\n<li>init_method(str，optional): 用来初始化包的URL, 我理解是一个用来做并发控制的共享方式</li>\n<li>world_size(int, optional): 参与这个工作的进程数</li>\n<li>rank(int,optional): 当前进程的rank</li>\n<li>group_name(str,optional): 用来标记这组进程名的</li>\n</ul>\n<p>其中初始化方式有三种：</p>\n<ol>\n<li>\n<p><strong>TCP initialization</strong><br>\ntcp:// IP组播（要求所有进程都在同一个网络中）比较好理解,   以TCP协议的方式进行不同分布式进程之间的数据交流，需要设置一个端口，不同进程之间公用这一个端口，并且设置host的级别和host的数量。设计两个参数rank和world_size。其中rank为host的编号，默认0为主机，端口应该位于该主机上。world_size为分布式主机的个数。<br>\n具体的可以初始化为：<code>tcp://127.0.0.1:12345</code></p>\n</li>\n<li>\n<p><strong>Shared file-system initialization</strong><br>\nfile:// 共享文件系统（要求所有进程可以访问单个文件系统）有共享文件系统可以选择<br>\n提供的第二种方式是文件共享，机器有共享的文件系统，故可以采用这种方式，也避免了基于TCP的网络传输。这里使用方式是使用绝对路径在指定一个共享文件系统下不存在的文件。<br>\n具体的：<code>file://PathToShareFile/MultiNode</code></p>\n</li>\n<li>\n<p><strong>Environment variable initialization</strong><br>\nenv:// 环境变量（需要您手动分配等级并知道所有进程可访问节点的地址）默认是这个</p>\n</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MASTER_PORT - required; has to be a free port on machine with rank 0</span><br><span class=\"line\">MASTER_ADDR - required (except for rank 0); address of rank 0 node</span><br><span class=\"line\">WORLD_SIZE - required; can be set either here, or in a call to init function</span><br><span class=\"line\">RANK - required; can be set either here, or in a call to init function</span><br></pre></td></tr></table></figure>\n<p>官方示例：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Node 1: (IP: 192.168.1.1, and has a free port: 1234)</span><br><span class=\"line\"> </span><br><span class=\"line\">&gt;&gt;&gt; python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE</span><br><span class=\"line\">           --nnodes=2 --node_rank=0 --master_addr=&quot;192.168.1.1&quot;</span><br><span class=\"line\">           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3</span><br><span class=\"line\">           and all other arguments of your training script)</span><br><span class=\"line\">Node 2:</span><br><span class=\"line\"> </span><br><span class=\"line\">&gt;&gt;&gt; python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE</span><br><span class=\"line\">           --nnodes=2 --node_rank=1 --master_addr=&quot;192.168.1.1&quot;</span><br><span class=\"line\">           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3</span><br><span class=\"line\">           and all other arguments of your training script)</span><br></pre></td></tr></table></figure>\n<p>在代码中进行初始化时，需要注意的一点是由于需要创建N个进程分别运行在0到N-1号GPU上，因此需要在代码中手动进行指定代码运行的GPU号，使用如下代码：</p>\n<blockquote>\n<p>torch.cuda.set_device(i)<br>\n其中i是0到N-1中的一个。同时在代码中也应该做如下的指定操作：</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.distributed.init_process_group(backend=&apos;nccl&apos;, world_size=4, rank=, init_method=&apos;...&apos;)</span><br><span class=\"line\">model = DistributedDataParallel(model, device_ids=[i], output_device=i)</span><br></pre></td></tr></table></figure>\n<p>在<code>torch.distributed.init_process_group()</code>中word_size与rank参数是必需的。代表了工作的进程数与当前进程的rank。<br>\n接下来可以启动进行分布式训练，官方也提供了相应的启动方式。</p>\n<h4 id=\"启动方式\"><a class=\"markdownIt-Anchor\" href=\"#启动方式\"></a> 启动方式</h4>\n<p>在<code>torch.distributed</code>当中提供了一个用于启动的程序<code>torch.distributed.launch</code>，此帮助程序可用于为每个节点启动多个进程以进行分布式训练，它在每个训练节点上产生多个分布式训练进程。<br>\n这个工具可以用作CPU或者GPU，如果被用于GPU，每个GPU产生一个进程进行训练。</p>\n<p>该工具既可以用来做单节点多GPU训练，也可用于多节点多GPU训练。如果是单节点多GPU，将会在单个GPU上运行一个分布式进程，据称可以非常好地改进单节点训练性能。如果用于多节点分布式训练，则通过在每个节点上产生多个进程来获得更好的多节点分布式训练性能。如果有Infiniband接口则加速比会更高。</p>\n<p>在单节点分布式训练或多节点分布式训练的两种情况下，该工具将为每个节点启动给定数量的进程（–nproc_per_node）。如果用于GPU培训，则此数字需要小于或等于当前系统上的GPU数量（nproc_per_node），并且每个进程将在从GPU 0到GPU（nproc_per_node - 1）的单个GPU上运行。<br>\n启动的命令为：</p>\n<blockquote>\n<p>python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE<br>\nYOUR_TRAINING_SCRIPT.py (–arg1 --arg2 --arg3 and all other<br>\narguments of your training script</p>\n</blockquote>\n<p><strong>注意</strong> 使用启动工具进行启动时，会产生<code>--local_rank</code>参数，需要在代码中使用如下类似代码处理：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import argparser</span><br><span class=\"line\"></span><br><span class=\"line\">parser = argparse.ArgumentParser()</span><br><span class=\"line\">parser.add_argument(&apos;--local_rank&apos;, type=int, ...)</span><br><span class=\"line\">args = parser..parse_args()</span><br></pre></td></tr></table></figure>\n<p>这一参数的作用是为各个进程分配rank号，因此可以直接使用这个<code>local_rank</code>参数作为<code>torch.distributed.init_process_group()</code>当中的参数rank，同时也可以作为</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.distributed.init_process_group(backend=&apos;nccl&apos;, world_size=4, rank=, init_method=&apos;...&apos;)</span><br><span class=\"line\">model = DistributedDataParallel(model, device_ids=[i], output_device=i)</span><br></pre></td></tr></table></figure>\n<p>中的i。</p>\n<h2 id=\"多机使用多个gpu\"><a class=\"markdownIt-Anchor\" href=\"#多机使用多个gpu\"></a> 多机使用多个GPU</h2>\n<p>相比于单机使用多个GPu，最大的区别在于启动方式的不同，假设有两个节点时：<br>\nNode 1: (IP: 192.168.1.1, and has a free port: 1234)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE</span><br><span class=\"line\">           --nnodes=2 --node_rank=0 --master_addr=&quot;192.168.1.1&quot;</span><br><span class=\"line\">           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3</span><br><span class=\"line\">           and all other arguments of your training script)</span><br></pre></td></tr></table></figure>\n<p>Node 2:</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt;&gt;&gt; python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE</span><br><span class=\"line\">           --nnodes=2 --node_rank=1 --master_addr=&quot;192.168.1.1&quot;</span><br><span class=\"line\">           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3</span><br><span class=\"line\">           and all other arguments of your training script)</span><br></pre></td></tr></table></figure>\n<p>增加的参数有nnodes代表机器即节点的个数，node_rank代表节点的rank，master-addr，master_port代表主节点的地址与端口号用于通信。<br>\n至此就介绍完了pytorch的分布式训练的基础内容。</p>\n<h2 id=\"参考\"><a class=\"markdownIt-Anchor\" href=\"#参考\"></a> 参考</h2>\n<p><a href=\"https://pytorch.org/docs/master/distributed.html\" target=\"_blank\" rel=\"noopener\">https://pytorch.org/docs/master/distributed.html</a><br>\n<a href=\"https://blog.csdn.net/zwqjoy/article/details/89415933\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zwqjoy/article/details/89415933</a><br>\n<a href=\"https://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py\" target=\"_blank\" rel=\"noopener\">https://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py</a><br>\n<a href=\"https://www.jianshu.com/p/be9f8b90a1b8?utm_campaign=hugo&amp;utm_medium=reader_share&amp;utm_content=note&amp;utm_source=weixin-friends\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/be9f8b90a1b8?utm_campaign=hugo&amp;utm_medium=reader_share&amp;utm_content=note&amp;utm_source=weixin-friends</a><br>\n<a href=\"https://juejin.im/entry/5c5f94fd518825629a779f51\" target=\"_blank\" rel=\"noopener\">https://juejin.im/entry/5c5f94fd518825629a779f51</a></p>\n"},{"title":"机器学习笔记（一）贝叶斯分类器","date":"2018-10-18T01:53:16.000Z","header-img":"PrpjzD1Q/bayes2.jpg","_content":"\n# 机器学习笔记（一）贝叶斯分类器\n\n## 前言\n虽然前一两年就陆陆续续的了解了不少机器学习相关的知识，也在Coursera上学完了Andrew Ng的课程，但知识整体比较零碎，现在上了研究生开始上机器学习这一门课，算是比较系统的学习各个机器学习算法，因此做一些记录与总结。一方面起到课后复习汇总要点的作用，另一方面也便于日后用的时候能够立马找到参考。\n整体顺序将按照课程的顺序来，首先是与贝叶斯分类器相关的东西\n\n## 贝叶斯决策论\n贝叶斯决策论的基本思想可以归结为利用贝叶斯公式将已知的类条件概率密度与先验概率转换为后验概率，并依据后验概率的大小进行分类\n这里有必要复习一下先验概率与后验概率\n> **先验概率** 先验概率是指根据以往经验分析得到的结果，也可理解为统计概率，通常可以通过对数据中类别出现次数的统计得到类别的先验概率\n> **后验概率** 后验概率是指无法通过经验分析得到，需要根据先验概率与似然函数计算得到，可理解为某件事情已经发生，则引起该事件发生的各个因素的概率即为后验概率\n> **似然函数** 似然函数是统计学中的一个概念，是关于统计模型中参数的函数，具体来说，在给定输出x时，关于参数$\\theta$的似然函数$L(\\theta \\mid x)$等于给定参数$\\theta$后变量X的概率：$L(\\theta \\mid x) = P(X=x\\mid \\theta)$\n可以理解为我们要找到一个关于参数$\\theta$的函数来拟合已有的数据\n\n根据以上，贝叶斯公式可以表示为：\n$$posterior = {likelihood*prior \\over evidence}$$\n即\n$$P(c\\mid x) = {P(x\\mid c)P(c)\\over p(x)}$$\n其中$P(c\\mid x)$是我们希望求得的后验概率，$P(c)$是类的先验概率，$P(x\\mid c)$是类条件概率，通常可以通过似然函数使用极大似然估计计算出来。$P(x)$是用于归一化的证据因子，它对所有类别均相同，即与分类无关，可以当做一个已知的量。因此估计$P(c\\mid x)$的问题可以转化为利用现有数据训练估计先验概率$P(c)$与类别条件概率$P(c\\mid x)$\n\n为了衡量贝叶斯决策的分类效果，同时使用贝叶斯决策得到最好的分类效果，我们同时应定义错误率或者说条件风险。这里我们简化采用最小化分类错误率，我们可以将误判损失写为：\n* 若分类正确则$\\lambda = 0$\n* 若分类错误则$\\lambda = 1$\n\n此时条件风险为：\n$$R(c\\mid x) = 1 - \\lambda P(c\\mid x) = 1-P(c\\mid x)$$\n于是可以得到最小分类错误率的最优贝叶斯分类器为：\n$$h^*(x) = arg maxP(c\\mid x)$$\n即对每个样本x，选择能使后验概率$P(c\\mid x)$最大的类别标记\n根据前面，使后验概率最大可以转化为使类条件概率与先验概率的成绩最大，即：\n$$h^*(x) = arg maxP(c)P(x\\mid c)$$\n根据大数定律，当数据所包含的独立同分布的样本数量足够多时，$P(c)$可以通过计算频率近似得到。但类条件概率$P(x\\mid c)$无法通过频率计算得到，因为在现实中样本的取值可能是大于样本的数量的，即很多可能的取值在数据中没有出现，使用频率计算显然不可行。此时我们可以使用极大似然估计来对类条件概率进行估计。\n\n## 极大似然估计\n极大似然估计的思想即是使用上面所提到的释然函数的思想。首先假设所要估计的数据具有某种确定的概率分布形式，再根据数据对概率分布的参数进行估计，也便是找到一个概率分布对我们的数据进行拟合。具体地，我们想要估计$P(x\\mid c)$的概率分布，我们可以将其记为$P(x\\mid \\theta_c)$。接下来我们可以使用似然函数对参数$\\theta$进行估计。事实上，概率模型的训练过程就是参数估计的过程。\n在这里，似然函数可以写为：\n\n$$\\hat{\\theta}= arg maxLL(\\theta_c)$$\n具体如何取得最大值可以视似然函数的情况而定\n总结：极大似然函数就是试图在$\\theta_c$的所有可能中，中到一个能使数据出现的可能性最大的值\n\n## 朴素贝叶斯分类器\n在上面的式子中，我们需要求得$P(x\\mid c)$，但这里的$P(x\\mid c)$是在所有属性上的联合概率，即$x$表示的各个属性可能是有相互关联的，若要直接计算具有较大难度，而朴素贝叶斯分类器采取了条件独立性假设来避免复杂的计算，即假设各个属性之间是相互独立的。换句话说，即各个属性对于最终的分类独立地产生影响。“朴素”即指假设的**属性相互独立**这一条件，同时另外还有半朴素贝叶斯分类，此处不表。\n在此基础上，我们可以得到贝叶斯分类器的表示形式：\n$$h_{nb}(x) = arg maxP(c)\\prod_{i = 1}^dP(x_i\\mid c)$$\n朴素贝叶斯分类器的训练过程可以总结为使用给定的训练集D估计先验概率$P(c)$和类别条件概率$P(x_i\\mid c)$\n\n## 拉普拉斯平滑\n上面说到在计算类表条件概率$P(x\\mid c)$时需要使用极大似然估计去找到一个能够较好拟合数据的关于属性的概率分布，事实上，在计算离散属性时，我们可以使用频率来近似估计类别c中某属性出现的概率，并作为类别条件概率用于计算。例如，对语文本分类问题，我们可以统计某类文本中某个词的出现次数作为其条件概率用于计算。但使用这种方法时仍然会遇到我们上面提到的问题，即如果在数据中某个属性的某个取值没有出现，那么该取值的类别条件概率就为0，这样计算下来最终得到的后验概率也为0，这样显然是不合理的，我们可以使用拉普拉斯平滑来解决这一问题。\n我们使用$D_c$表示数据集D中分类为c的样本组成的集合，使用$D_{c, x_i}$表示$D_C$中第i个属性取值为$x_i$的样本组成的集合。不考虑平滑时计算公式为：\n$$P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| \\over \\left|D_{c}\\right|} $$\n我们令$N_c$表示类别c的可能取值的数量，$N_i$表示属性$x_i$的可能取值的数量，采用拉普拉斯平滑修正后的式子为：\n$$P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| + 1 \\over \\left|D_{c}\\right| + N_c} $$\n同时，计算先验概率的式子也变换为：\n$$P(c) = {\\left|D_{c}\\right| + 1 \\over \\left|D \\right| + N_c}$$\n更一般地，可以使用参数$\\lambda$代替简单的加1，即：\n$$P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| + \\lambda \\over \\left|D_{c}\\right| + \\lambda N_c} $$\n同理：\n$$P(c) = {\\left|D_{c}\\right| + \\lambda \\over \\left|D \\right| + \\lambda N_c}$$\n采用这种方法可以避免由于数据不充分带来的概率估计值为0的问题。事实上，拉普拉斯平滑假设了类别与属性的均匀分布，算是额外引入的先验。\n\n\n","source":"_posts/机器学习笔记（一）贝叶斯分类器.md","raw":"---\ntitle: 机器学习笔记（一）贝叶斯分类器\ndate: 2018-10-18 09:53:16\nheader-img: PrpjzD1Q/bayes2.jpg\ntags: Machine Learning\n---\n\n# 机器学习笔记（一）贝叶斯分类器\n\n## 前言\n虽然前一两年就陆陆续续的了解了不少机器学习相关的知识，也在Coursera上学完了Andrew Ng的课程，但知识整体比较零碎，现在上了研究生开始上机器学习这一门课，算是比较系统的学习各个机器学习算法，因此做一些记录与总结。一方面起到课后复习汇总要点的作用，另一方面也便于日后用的时候能够立马找到参考。\n整体顺序将按照课程的顺序来，首先是与贝叶斯分类器相关的东西\n\n## 贝叶斯决策论\n贝叶斯决策论的基本思想可以归结为利用贝叶斯公式将已知的类条件概率密度与先验概率转换为后验概率，并依据后验概率的大小进行分类\n这里有必要复习一下先验概率与后验概率\n> **先验概率** 先验概率是指根据以往经验分析得到的结果，也可理解为统计概率，通常可以通过对数据中类别出现次数的统计得到类别的先验概率\n> **后验概率** 后验概率是指无法通过经验分析得到，需要根据先验概率与似然函数计算得到，可理解为某件事情已经发生，则引起该事件发生的各个因素的概率即为后验概率\n> **似然函数** 似然函数是统计学中的一个概念，是关于统计模型中参数的函数，具体来说，在给定输出x时，关于参数$\\theta$的似然函数$L(\\theta \\mid x)$等于给定参数$\\theta$后变量X的概率：$L(\\theta \\mid x) = P(X=x\\mid \\theta)$\n可以理解为我们要找到一个关于参数$\\theta$的函数来拟合已有的数据\n\n根据以上，贝叶斯公式可以表示为：\n$$posterior = {likelihood*prior \\over evidence}$$\n即\n$$P(c\\mid x) = {P(x\\mid c)P(c)\\over p(x)}$$\n其中$P(c\\mid x)$是我们希望求得的后验概率，$P(c)$是类的先验概率，$P(x\\mid c)$是类条件概率，通常可以通过似然函数使用极大似然估计计算出来。$P(x)$是用于归一化的证据因子，它对所有类别均相同，即与分类无关，可以当做一个已知的量。因此估计$P(c\\mid x)$的问题可以转化为利用现有数据训练估计先验概率$P(c)$与类别条件概率$P(c\\mid x)$\n\n为了衡量贝叶斯决策的分类效果，同时使用贝叶斯决策得到最好的分类效果，我们同时应定义错误率或者说条件风险。这里我们简化采用最小化分类错误率，我们可以将误判损失写为：\n* 若分类正确则$\\lambda = 0$\n* 若分类错误则$\\lambda = 1$\n\n此时条件风险为：\n$$R(c\\mid x) = 1 - \\lambda P(c\\mid x) = 1-P(c\\mid x)$$\n于是可以得到最小分类错误率的最优贝叶斯分类器为：\n$$h^*(x) = arg maxP(c\\mid x)$$\n即对每个样本x，选择能使后验概率$P(c\\mid x)$最大的类别标记\n根据前面，使后验概率最大可以转化为使类条件概率与先验概率的成绩最大，即：\n$$h^*(x) = arg maxP(c)P(x\\mid c)$$\n根据大数定律，当数据所包含的独立同分布的样本数量足够多时，$P(c)$可以通过计算频率近似得到。但类条件概率$P(x\\mid c)$无法通过频率计算得到，因为在现实中样本的取值可能是大于样本的数量的，即很多可能的取值在数据中没有出现，使用频率计算显然不可行。此时我们可以使用极大似然估计来对类条件概率进行估计。\n\n## 极大似然估计\n极大似然估计的思想即是使用上面所提到的释然函数的思想。首先假设所要估计的数据具有某种确定的概率分布形式，再根据数据对概率分布的参数进行估计，也便是找到一个概率分布对我们的数据进行拟合。具体地，我们想要估计$P(x\\mid c)$的概率分布，我们可以将其记为$P(x\\mid \\theta_c)$。接下来我们可以使用似然函数对参数$\\theta$进行估计。事实上，概率模型的训练过程就是参数估计的过程。\n在这里，似然函数可以写为：\n\n$$\\hat{\\theta}= arg maxLL(\\theta_c)$$\n具体如何取得最大值可以视似然函数的情况而定\n总结：极大似然函数就是试图在$\\theta_c$的所有可能中，中到一个能使数据出现的可能性最大的值\n\n## 朴素贝叶斯分类器\n在上面的式子中，我们需要求得$P(x\\mid c)$，但这里的$P(x\\mid c)$是在所有属性上的联合概率，即$x$表示的各个属性可能是有相互关联的，若要直接计算具有较大难度，而朴素贝叶斯分类器采取了条件独立性假设来避免复杂的计算，即假设各个属性之间是相互独立的。换句话说，即各个属性对于最终的分类独立地产生影响。“朴素”即指假设的**属性相互独立**这一条件，同时另外还有半朴素贝叶斯分类，此处不表。\n在此基础上，我们可以得到贝叶斯分类器的表示形式：\n$$h_{nb}(x) = arg maxP(c)\\prod_{i = 1}^dP(x_i\\mid c)$$\n朴素贝叶斯分类器的训练过程可以总结为使用给定的训练集D估计先验概率$P(c)$和类别条件概率$P(x_i\\mid c)$\n\n## 拉普拉斯平滑\n上面说到在计算类表条件概率$P(x\\mid c)$时需要使用极大似然估计去找到一个能够较好拟合数据的关于属性的概率分布，事实上，在计算离散属性时，我们可以使用频率来近似估计类别c中某属性出现的概率，并作为类别条件概率用于计算。例如，对语文本分类问题，我们可以统计某类文本中某个词的出现次数作为其条件概率用于计算。但使用这种方法时仍然会遇到我们上面提到的问题，即如果在数据中某个属性的某个取值没有出现，那么该取值的类别条件概率就为0，这样计算下来最终得到的后验概率也为0，这样显然是不合理的，我们可以使用拉普拉斯平滑来解决这一问题。\n我们使用$D_c$表示数据集D中分类为c的样本组成的集合，使用$D_{c, x_i}$表示$D_C$中第i个属性取值为$x_i$的样本组成的集合。不考虑平滑时计算公式为：\n$$P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| \\over \\left|D_{c}\\right|} $$\n我们令$N_c$表示类别c的可能取值的数量，$N_i$表示属性$x_i$的可能取值的数量，采用拉普拉斯平滑修正后的式子为：\n$$P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| + 1 \\over \\left|D_{c}\\right| + N_c} $$\n同时，计算先验概率的式子也变换为：\n$$P(c) = {\\left|D_{c}\\right| + 1 \\over \\left|D \\right| + N_c}$$\n更一般地，可以使用参数$\\lambda$代替简单的加1，即：\n$$P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| + \\lambda \\over \\left|D_{c}\\right| + \\lambda N_c} $$\n同理：\n$$P(c) = {\\left|D_{c}\\right| + \\lambda \\over \\left|D \\right| + \\lambda N_c}$$\n采用这种方法可以避免由于数据不充分带来的概率估计值为0的问题。事实上，拉普拉斯平滑假设了类别与属性的均匀分布，算是额外引入的先验。\n\n\n","slug":"机器学习笔记（一）贝叶斯分类器","published":1,"updated":"2018-10-24T02:20:53.935Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjv0dq3ry000247od9em0qb4o","content":"<h1 id=\"机器学习笔记一贝叶斯分类器\"><a class=\"markdownIt-Anchor\" href=\"#机器学习笔记一贝叶斯分类器\"></a> 机器学习笔记（一）贝叶斯分类器</h1>\n<h2 id=\"前言\"><a class=\"markdownIt-Anchor\" href=\"#前言\"></a> 前言</h2>\n<p>虽然前一两年就陆陆续续的了解了不少机器学习相关的知识，也在Coursera上学完了Andrew Ng的课程，但知识整体比较零碎，现在上了研究生开始上机器学习这一门课，算是比较系统的学习各个机器学习算法，因此做一些记录与总结。一方面起到课后复习汇总要点的作用，另一方面也便于日后用的时候能够立马找到参考。<br>\n整体顺序将按照课程的顺序来，首先是与贝叶斯分类器相关的东西</p>\n<h2 id=\"贝叶斯决策论\"><a class=\"markdownIt-Anchor\" href=\"#贝叶斯决策论\"></a> 贝叶斯决策论</h2>\n<p>贝叶斯决策论的基本思想可以归结为利用贝叶斯公式将已知的类条件概率密度与先验概率转换为后验概率，并依据后验概率的大小进行分类<br>\n这里有必要复习一下先验概率与后验概率</p>\n<blockquote>\n<p><strong>先验概率</strong> 先验概率是指根据以往经验分析得到的结果，也可理解为统计概率，通常可以通过对数据中类别出现次数的统计得到类别的先验概率<br>\n<strong>后验概率</strong> 后验概率是指无法通过经验分析得到，需要根据先验概率与似然函数计算得到，可理解为某件事情已经发生，则引起该事件发生的各个因素的概率即为后验概率<br>\n<strong>似然函数</strong> 似然函数是统计学中的一个概念，是关于统计模型中参数的函数，具体来说，在给定输出x时，关于参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>的似然函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">L(\\theta \\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">L</span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>等于给定参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>后变量X的概率：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>∣</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">L(\\theta \\mid x) = P(X=x\\mid \\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">L</span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"mrel\">=</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span><br>\n可以理解为我们要找到一个关于参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>的函数来拟合已有的数据</p>\n</blockquote>\n<p>根据以上，贝叶斯公式可以表示为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>o</mi><mi>r</mi><mo>=</mo><mrow><mfrac><mrow><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mi>l</mi><mi>i</mi><mi>h</mi><mi>o</mi><mi>o</mi><mi>d</mi><mo>∗</mo><mi>p</mi><mi>r</mi><mi>i</mi><mi>o</mi><mi>r</mi></mrow><mrow><mi>e</mi><mi>v</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">posterior = {likelihood*prior \\over evidence}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.37144em;\"></span><span class=\"strut bottom\" style=\"height:2.05744em;vertical-align:-0.686em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">p</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\">s</span><span class=\"mord mathit\">t</span><span class=\"mord mathit\">e</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"mord mathit\">e</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">e</span><span class=\"mord mathit\">n</span><span class=\"mord mathit\">c</span><span class=\"mord mathit\">e</span></span></span></span><span style=\"top:-0.22999999999999998em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span><span class=\"mord mathit\">e</span><span class=\"mord mathit\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\">h</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\">d</span><span class=\"mbin\">∗</span><span class=\"mord mathit\">p</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>即</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x) = {P(x\\mid c)P(c)\\over p(x)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"mord mathit\">p</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>其中<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>是我们希望求得的后验概率，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>是类的先验概率，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>是类条件概率，通常可以通过似然函数使用极大似然估计计算出来。<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>是用于归一化的证据因子，它对所有类别均相同，即与分类无关，可以当做一个已知的量。因此估计<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>的问题可以转化为利用现有数据训练估计先验概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>与类别条件概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span></p>\n<p>为了衡量贝叶斯决策的分类效果，同时使用贝叶斯决策得到最好的分类效果，我们同时应定义错误率或者说条件风险。这里我们简化采用最小化分类错误率，我们可以将误判损失写为：</p>\n<ul>\n<li>若分类正确则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">λ</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">0</span></span></span></span></li>\n<li>若分类错误则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">λ</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span></span></span></span></li>\n</ul>\n<p>此时条件风险为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>R</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">R(c\\mid x) = 1 - \\lambda P(c\\mid x) = 1-P(c\\mid x)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathit\">λ</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>于是可以得到最小分类错误率的最优贝叶斯分类器为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>h</mi><mo>∗</mo></msup><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">h^*(x) = arg maxP(c\\mid x)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">h</span><span class=\"vlist\"><span style=\"top:-0.413em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord\">∗</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>即对每个样本x，选择能使后验概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>最大的类别标记<br>\n根据前面，使后验概率最大可以转化为使类条件概率与先验概率的成绩最大，即：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>h</mi><mo>∗</mo></msup><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">h^*(x) = arg maxP(c)P(x\\mid c)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">h</span><span class=\"vlist\"><span style=\"top:-0.413em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord\">∗</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>根据大数定律，当数据所包含的独立同分布的样本数量足够多时，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>可以通过计算频率近似得到。但类条件概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>无法通过频率计算得到，因为在现实中样本的取值可能是大于样本的数量的，即很多可能的取值在数据中没有出现，使用频率计算显然不可行。此时我们可以使用极大似然估计来对类条件概率进行估计。</p>\n<h2 id=\"极大似然估计\"><a class=\"markdownIt-Anchor\" href=\"#极大似然估计\"></a> 极大似然估计</h2>\n<p>极大似然估计的思想即是使用上面所提到的释然函数的思想。首先假设所要估计的数据具有某种确定的概率分布形式，再根据数据对概率分布的参数进行估计，也便是找到一个概率分布对我们的数据进行拟合。具体地，我们想要估计<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>的概率分布，我们可以将其记为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><msub><mi>θ</mi><mi>c</mi></msub><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid \\theta_c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mclose\">)</span></span></span></span>。接下来我们可以使用似然函数对参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>进行估计。事实上，概率模型的训练过程就是参数估计的过程。<br>\n在这里，似然函数可以写为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>θ</mi></mrow><mo>^</mo></mover><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mi>L</mi><mi>L</mi><mo>(</mo><msub><mi>θ</mi><mi>c</mi></msub><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{\\theta}= arg maxLL(\\theta_c)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9578799999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.2078799999999998em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord accent\"><span class=\"vlist\"><span style=\"top:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"mord displaystyle textstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-0.26343999999999995em;margin-left:0.16668em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"accent-body\"><span>^</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">=</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\">L</span><span class=\"mord mathit\">L</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>具体如何取得最大值可以视似然函数的情况而定<br>\n总结：极大似然函数就是试图在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mi>c</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>的所有可能中，中到一个能使数据出现的可能性最大的值</p>\n<h2 id=\"朴素贝叶斯分类器\"><a class=\"markdownIt-Anchor\" href=\"#朴素贝叶斯分类器\"></a> 朴素贝叶斯分类器</h2>\n<p>在上面的式子中，我们需要求得<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>，但这里的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>是在所有属性上的联合概率，即<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">x</span></span></span></span>表示的各个属性可能是有相互关联的，若要直接计算具有较大难度，而朴素贝叶斯分类器采取了条件独立性假设来避免复杂的计算，即假设各个属性之间是相互独立的。换句话说，即各个属性对于最终的分类独立地产生影响。“朴素”即指假设的<strong>属性相互独立</strong>这一条件，同时另外还有半朴素贝叶斯分类，此处不表。<br>\n在此基础上，我们可以得到贝叶斯分类器的表示形式：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>n</mi><mi>b</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo><msubsup><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></msubsup><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">h_{nb}(x) = arg maxP(c)\\prod_{i = 1}^dP(x_i\\mid c)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.8361130000000003em;\"></span><span class=\"strut bottom\" style=\"height:3.1137820000000005em;vertical-align:-1.277669em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">h</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">n</span><span class=\"mord mathit\">b</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mop op-limits\"><span class=\"vlist\"><span style=\"top:1.1776689999999999em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span></span></span></span><span style=\"top:-0.000005000000000143778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span><span class=\"op-symbol large-op mop\">∏</span></span></span><span style=\"top:-1.2500050000000003em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord mathit\">d</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>朴素贝叶斯分类器的训练过程可以总结为使用给定的训练集D估计先验概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>和类别条件概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x_i\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span></p>\n<h2 id=\"拉普拉斯平滑\"><a class=\"markdownIt-Anchor\" href=\"#拉普拉斯平滑\"></a> 拉普拉斯平滑</h2>\n<p>上面说到在计算类表条件概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>时需要使用极大似然估计去找到一个能够较好拟合数据的关于属性的概率分布，事实上，在计算离散属性时，我们可以使用频率来近似估计类别c中某属性出现的概率，并作为类别条件概率用于计算。例如，对语文本分类问题，我们可以统计某类文本中某个词的出现次数作为其条件概率用于计算。但使用这种方法时仍然会遇到我们上面提到的问题，即如果在数据中某个属性的某个取值没有出现，那么该取值的类别条件概率就为0，这样计算下来最终得到的后验概率也为0，这样显然是不合理的，我们可以使用拉普拉斯平滑来解决这一问题。<br>\n我们使用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mi>c</mi></msub></mrow><annotation encoding=\"application/x-tex\">D_c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>表示数据集D中分类为c的样本组成的集合，使用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mrow><mi>c</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msub></mrow><annotation encoding=\"application/x-tex\">D_{c, x_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>表示<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mi>C</mi></msub></mrow><annotation encoding=\"application/x-tex\">D_C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.07153em;\">C</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>中第i个属性取值为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>的样本组成的集合。不考虑平滑时计算公式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msub><mo fence=\"true\">∣</mo></mrow></mrow><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| \\over \\left|D_{c}\\right|} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>我们令<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>N</mi><mi>c</mi></msub></mrow><annotation encoding=\"application/x-tex\">N_c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>表示类别c的可能取值的数量，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>N</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">N_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>表示属性<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>的可能取值的数量，采用拉普拉斯平滑修正后的式子为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mn>1</mn></mrow><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><msub><mi>N</mi><mi>c</mi></msub></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| + 1 \\over \\left|D_{c}\\right| + N_c} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>同时，计算先验概率的式子也变换为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mn>1</mn></mrow><mrow><mrow><mo fence=\"true\">∣</mo><mi>D</mi><mo fence=\"true\">∣</mo></mrow><mo>+</mo><msub><mi>N</mi><mi>c</mi></msub></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(c) = {\\left|D_{c}\\right| + 1 \\over \\left|D \\right| + N_c}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>更一般地，可以使用参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">λ</span></span></span></span>代替简单的加1，即：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mi>λ</mi></mrow><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mi>λ</mi><msub><mi>N</mi><mi>c</mi></msub></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| + \\lambda \\over \\left|D_{c}\\right| + \\lambda N_c} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>同理：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mi>λ</mi></mrow><mrow><mrow><mo fence=\"true\">∣</mo><mi>D</mi><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mi>λ</mi><msub><mi>N</mi><mi>c</mi></msub></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(c) = {\\left|D_{c}\\right| + \\lambda \\over \\left|D \\right| + \\lambda N_c}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>采用这种方法可以避免由于数据不充分带来的概率估计值为0的问题。事实上，拉普拉斯平滑假设了类别与属性的均匀分布，算是额外引入的先验。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"机器学习笔记一贝叶斯分类器\"><a class=\"markdownIt-Anchor\" href=\"#机器学习笔记一贝叶斯分类器\"></a> 机器学习笔记（一）贝叶斯分类器</h1>\n<h2 id=\"前言\"><a class=\"markdownIt-Anchor\" href=\"#前言\"></a> 前言</h2>\n<p>虽然前一两年就陆陆续续的了解了不少机器学习相关的知识，也在Coursera上学完了Andrew Ng的课程，但知识整体比较零碎，现在上了研究生开始上机器学习这一门课，算是比较系统的学习各个机器学习算法，因此做一些记录与总结。一方面起到课后复习汇总要点的作用，另一方面也便于日后用的时候能够立马找到参考。<br>\n整体顺序将按照课程的顺序来，首先是与贝叶斯分类器相关的东西</p>\n<h2 id=\"贝叶斯决策论\"><a class=\"markdownIt-Anchor\" href=\"#贝叶斯决策论\"></a> 贝叶斯决策论</h2>\n<p>贝叶斯决策论的基本思想可以归结为利用贝叶斯公式将已知的类条件概率密度与先验概率转换为后验概率，并依据后验概率的大小进行分类<br>\n这里有必要复习一下先验概率与后验概率</p>\n<blockquote>\n<p><strong>先验概率</strong> 先验概率是指根据以往经验分析得到的结果，也可理解为统计概率，通常可以通过对数据中类别出现次数的统计得到类别的先验概率<br>\n<strong>后验概率</strong> 后验概率是指无法通过经验分析得到，需要根据先验概率与似然函数计算得到，可理解为某件事情已经发生，则引起该事件发生的各个因素的概率即为后验概率<br>\n<strong>似然函数</strong> 似然函数是统计学中的一个概念，是关于统计模型中参数的函数，具体来说，在给定输出x时，关于参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>的似然函数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">L(\\theta \\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">L</span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>等于给定参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>后变量X的概率：<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>(</mo><mi>θ</mi><mo>∣</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>P</mi><mo>(</mo><mi>X</mi><mo>=</mo><mi>x</mi><mo>∣</mo><mi>θ</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">L(\\theta \\mid x) = P(X=x\\mid \\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">L</span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right:0.07847em;\">X</span><span class=\"mrel\">=</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose\">)</span></span></span></span><br>\n可以理解为我们要找到一个关于参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>的函数来拟合已有的数据</p>\n</blockquote>\n<p>根据以上，贝叶斯公式可以表示为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>o</mi><mi>r</mi><mo>=</mo><mrow><mfrac><mrow><mi>l</mi><mi>i</mi><mi>k</mi><mi>e</mi><mi>l</mi><mi>i</mi><mi>h</mi><mi>o</mi><mi>o</mi><mi>d</mi><mo>∗</mo><mi>p</mi><mi>r</mi><mi>i</mi><mi>o</mi><mi>r</mi></mrow><mrow><mi>e</mi><mi>v</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">posterior = {likelihood*prior \\over evidence}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.37144em;\"></span><span class=\"strut bottom\" style=\"height:2.05744em;vertical-align:-0.686em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\">p</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\">s</span><span class=\"mord mathit\">t</span><span class=\"mord mathit\">e</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"mord mathit\">e</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\">d</span><span class=\"mord mathit\">e</span><span class=\"mord mathit\">n</span><span class=\"mord mathit\">c</span><span class=\"mord mathit\">e</span></span></span></span><span style=\"top:-0.22999999999999998em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\" style=\"margin-right:0.03148em;\">k</span><span class=\"mord mathit\">e</span><span class=\"mord mathit\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\">h</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\">d</span><span class=\"mbin\">∗</span><span class=\"mord mathit\">p</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\">i</span><span class=\"mord mathit\">o</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>即</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><mrow><mi>p</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x) = {P(x\\mid c)P(c)\\over p(x)}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"mord mathit\">p</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>其中<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>是我们希望求得的后验概率，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>是类的先验概率，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>是类条件概率，通常可以通过似然函数使用极大似然估计计算出来。<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>是用于归一化的证据因子，它对所有类别均相同，即与分类无关，可以当做一个已知的量。因此估计<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>的问题可以转化为利用现有数据训练估计先验概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>与类别条件概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span></p>\n<p>为了衡量贝叶斯决策的分类效果，同时使用贝叶斯决策得到最好的分类效果，我们同时应定义错误率或者说条件风险。这里我们简化采用最小化分类错误率，我们可以将误判损失写为：</p>\n<ul>\n<li>若分类正确则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">λ</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">0</span></span></span></span></li>\n<li>若分类错误则<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">\\lambda = 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">λ</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span></span></span></span></li>\n</ul>\n<p>此时条件风险为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>R</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>λ</mi><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo><mo>=</mo><mn>1</mn><mo>−</mo><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">R(c\\mid x) = 1 - \\lambda P(c\\mid x) = 1-P(c\\mid x)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathit\">λ</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span><span class=\"mbin\">−</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>于是可以得到最小分类错误率的最优贝叶斯分类器为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>h</mi><mo>∗</mo></msup><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">h^*(x) = arg maxP(c\\mid x)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">h</span><span class=\"vlist\"><span style=\"top:-0.413em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord\">∗</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>即对每个样本x，选择能使后验概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>∣</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c\\mid x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span></span></span></span>最大的类别标记<br>\n根据前面，使后验概率最大可以转化为使类条件概率与先验概率的成绩最大，即：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msup><mi>h</mi><mo>∗</mo></msup><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">h^*(x) = arg maxP(c)P(x\\mid c)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">h</span><span class=\"vlist\"><span style=\"top:-0.413em;margin-right:0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord\">∗</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>根据大数定律，当数据所包含的独立同分布的样本数量足够多时，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>可以通过计算频率近似得到。但类条件概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>无法通过频率计算得到，因为在现实中样本的取值可能是大于样本的数量的，即很多可能的取值在数据中没有出现，使用频率计算显然不可行。此时我们可以使用极大似然估计来对类条件概率进行估计。</p>\n<h2 id=\"极大似然估计\"><a class=\"markdownIt-Anchor\" href=\"#极大似然估计\"></a> 极大似然估计</h2>\n<p>极大似然估计的思想即是使用上面所提到的释然函数的思想。首先假设所要估计的数据具有某种确定的概率分布形式，再根据数据对概率分布的参数进行估计，也便是找到一个概率分布对我们的数据进行拟合。具体地，我们想要估计<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>的概率分布，我们可以将其记为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><msub><mi>θ</mi><mi>c</mi></msub><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid \\theta_c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mclose\">)</span></span></span></span>。接下来我们可以使用似然函数对参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding=\"application/x-tex\">\\theta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span></span>进行估计。事实上，概率模型的训练过程就是参数估计的过程。<br>\n在这里，似然函数可以写为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><mrow><mi>θ</mi></mrow><mo>^</mo></mover><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mi>L</mi><mi>L</mi><mo>(</mo><msub><mi>θ</mi><mi>c</mi></msub><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{\\theta}= arg maxLL(\\theta_c)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.9578799999999998em;\"></span><span class=\"strut bottom\" style=\"height:1.2078799999999998em;vertical-align:-0.25em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord accent\"><span class=\"vlist\"><span style=\"top:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"mord displaystyle textstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span></span></span><span style=\"top:-0.26343999999999995em;margin-left:0.16668em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"accent-body\"><span>^</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">=</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\">L</span><span class=\"mord mathit\">L</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>具体如何取得最大值可以视似然函数的情况而定<br>\n总结：极大似然函数就是试图在<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>θ</mi><mi>c</mi></msub></mrow><annotation encoding=\"application/x-tex\">\\theta_c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.84444em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">θ</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>的所有可能中，中到一个能使数据出现的可能性最大的值</p>\n<h2 id=\"朴素贝叶斯分类器\"><a class=\"markdownIt-Anchor\" href=\"#朴素贝叶斯分类器\"></a> 朴素贝叶斯分类器</h2>\n<p>在上面的式子中，我们需要求得<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>，但这里的<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>是在所有属性上的联合概率，即<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">x</span></span></span></span>表示的各个属性可能是有相互关联的，若要直接计算具有较大难度，而朴素贝叶斯分类器采取了条件独立性假设来避免复杂的计算，即假设各个属性之间是相互独立的。换句话说，即各个属性对于最终的分类独立地产生影响。“朴素”即指假设的<strong>属性相互独立</strong>这一条件，同时另外还有半朴素贝叶斯分类，此处不表。<br>\n在此基础上，我们可以得到贝叶斯分类器的表示形式：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>n</mi><mi>b</mi></mrow></msub><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo><mi>a</mi><mi>r</mi><mi>g</mi><mi>m</mi><mi>a</mi><mi>x</mi><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo><msubsup><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></msubsup><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">h_{nb}(x) = arg maxP(c)\\prod_{i = 1}^dP(x_i\\mid c)\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.8361130000000003em;\"></span><span class=\"strut bottom\" style=\"height:3.1137820000000005em;vertical-align:-1.277669em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">h</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">n</span><span class=\"mord mathit\">b</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathit\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathit\">m</span><span class=\"mord mathit\">a</span><span class=\"mord mathit\">x</span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mop op-limits\"><span class=\"vlist\"><span style=\"top:1.1776689999999999em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">i</span><span class=\"mrel\">=</span><span class=\"mord mathrm\">1</span></span></span></span><span style=\"top:-0.000005000000000143778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span><span class=\"op-symbol large-op mop\">∏</span></span></span><span style=\"top:-1.2500050000000003em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord mathit\">d</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p>朴素贝叶斯分类器的训练过程可以总结为使用给定的训练集D估计先验概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>和类别条件概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x_i\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span></p>\n<h2 id=\"拉普拉斯平滑\"><a class=\"markdownIt-Anchor\" href=\"#拉普拉斯平滑\"></a> 拉普拉斯平滑</h2>\n<p>上面说到在计算类表条件概率<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>x</mi><mo>∣</mo><mi>c</mi><mo>)</mo></mrow><annotation encoding=\"application/x-tex\">P(x\\mid c)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.75em;\"></span><span class=\"strut bottom\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span></span></span></span>时需要使用极大似然估计去找到一个能够较好拟合数据的关于属性的概率分布，事实上，在计算离散属性时，我们可以使用频率来近似估计类别c中某属性出现的概率，并作为类别条件概率用于计算。例如，对语文本分类问题，我们可以统计某类文本中某个词的出现次数作为其条件概率用于计算。但使用这种方法时仍然会遇到我们上面提到的问题，即如果在数据中某个属性的某个取值没有出现，那么该取值的类别条件概率就为0，这样计算下来最终得到的后验概率也为0，这样显然是不合理的，我们可以使用拉普拉斯平滑来解决这一问题。<br>\n我们使用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mi>c</mi></msub></mrow><annotation encoding=\"application/x-tex\">D_c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>表示数据集D中分类为c的样本组成的集合，使用<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mrow><mi>c</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msub></mrow><annotation encoding=\"application/x-tex\">D_{c, x_i}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.969438em;vertical-align:-0.286108em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>表示<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>D</mi><mi>C</mi></msub></mrow><annotation encoding=\"application/x-tex\">D_C</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\" style=\"margin-right:0.07153em;\">C</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>中第i个属性取值为<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>的样本组成的集合。不考虑平滑时计算公式为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msub><mo fence=\"true\">∣</mo></mrow></mrow><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| \\over \\left|D_{c}\\right|} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>我们令<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>N</mi><mi>c</mi></msub></mrow><annotation encoding=\"application/x-tex\">N_c</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>表示类别c的可能取值的数量，<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>N</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">N_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.68333em;\"></span><span class=\"strut bottom\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>表示属性<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.43056em;\"></span><span class=\"strut bottom\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span>的可能取值的数量，采用拉普拉斯平滑修正后的式子为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mn>1</mn></mrow><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><msub><mi>N</mi><mi>c</mi></msub></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| + 1 \\over \\left|D_{c}\\right| + N_c} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>同时，计算先验概率的式子也变换为：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mn>1</mn></mrow><mrow><mrow><mo fence=\"true\">∣</mo><mi>D</mi><mo fence=\"true\">∣</mo></mrow><mo>+</mo><msub><mi>N</mi><mi>c</mi></msub></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(c) = {\\left|D_{c}\\right| + 1 \\over \\left|D \\right| + N_c}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathrm\">1</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>更一般地，可以使用参数<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:0.69444em;\"></span><span class=\"strut bottom\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\">λ</span></span></span></span>代替简单的加1，即：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>∣</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi><mo separator=\"true\">,</mo><msub><mi>x</mi><mi>i</mi></msub></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mi>λ</mi></mrow><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mi>λ</mi><msub><mi>N</mi><mi>c</mi></msub></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(x_i\\mid c) = {\\left|D_{c, x_i}\\right| + \\lambda \\over \\left|D_{c}\\right| + \\lambda N_c} \n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"mrel\">∣</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span><span class=\"mpunct\">,</span><span class=\"mord\"><span class=\"mord mathit\">x</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-scriptstyle scriptscriptstyle cramped\"><span class=\"mord mathit\">i</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>同理：</p>\n<p><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>P</mi><mo>(</mo><mi>c</mi><mo>)</mo><mo>=</mo><mrow><mfrac><mrow><mrow><mo fence=\"true\">∣</mo><msub><mi>D</mi><mrow><mi>c</mi></mrow></msub><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mi>λ</mi></mrow><mrow><mrow><mo fence=\"true\">∣</mo><mi>D</mi><mo fence=\"true\">∣</mo></mrow><mo>+</mo><mi>λ</mi><msub><mi>N</mi><mi>c</mi></msub></mrow></mfrac></mrow></mrow><annotation encoding=\"application/x-tex\">P(c) = {\\left|D_{c}\\right| + \\lambda \\over \\left|D \\right| + \\lambda N_c}\n</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height:1.427em;\"></span><span class=\"strut bottom\" style=\"height:2.363em;vertical-align:-0.936em;\"></span><span class=\"base displaystyle textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right:0.13889em;\">P</span><span class=\"mopen\">(</span><span class=\"mord mathit\">c</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord displaystyle textstyle uncramped\"><span class=\"mord reset-textstyle displaystyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span style=\"top:0.686em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle cramped\"><span class=\"mord textstyle cramped\"><span class=\"minner textstyle cramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.10903em;\">N</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.10903em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span></span></span></span><span style=\"top:-0.2300000000000001em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span style=\"top:-0.677em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span><span class=\"reset-textstyle textstyle uncramped\"><span class=\"mord textstyle uncramped\"><span class=\"minner textstyle uncramped\"><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span><span class=\"mord\"><span class=\"mord mathit\" style=\"margin-right:0.02778em;\">D</span><span class=\"vlist\"><span style=\"top:0.15em;margin-right:0.05em;margin-left:-0.02778em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">c</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:0em;\">​</span></span>​</span></span></span><span class=\"style-wrap reset-textstyle textstyle uncramped\" style=\"top:0em;\">∣</span></span><span class=\"mbin\">+</span><span class=\"mord mathit\">λ</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span style=\"font-size:1em;\">​</span></span>​</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span></span></span></span></span></span></p>\n<p>采用这种方法可以避免由于数据不充分带来的概率估计值为0的问题。事实上，拉普拉斯平滑假设了类别与属性的均匀分布，算是额外引入的先验。</p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cjv0dq3rt000047odzbs3gahz","tag_id":"cjv0dq3s1000447odh6q3ez1y","_id":"cjv0dq3s5000647od0mcbrhhf"},{"post_id":"cjv0dq3ry000247od9em0qb4o","tag_id":"cjv0dq3s4000547od813sx15a","_id":"cjv0dq3s6000747odvraxk14x"}],"Tag":[{"name":"PyTorch","_id":"cjv0dq3s1000447odh6q3ez1y"},{"name":"Machine Learning","_id":"cjv0dq3s4000547od813sx15a"}]}}